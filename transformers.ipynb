{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simplemma\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#попередня обробка тексту\n",
    "def ClearText(text):\n",
    "    #переведення до нижнього регістру всіх слів\n",
    "    cleartext = text.lower()\n",
    "    #print(cleartext)\n",
    "    #прибирання пустих рядків та розрив рядків\n",
    "    cleartext = re.sub('\\-\\s\\r\\n\\s{1,}|\\-\\s\\r\\n|\\r\\n', '', cleartext) \n",
    "    #залишаємо лише слова, прибираємо пунктуацію та числа\n",
    "    cleartext = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-', ' ', cleartext) #deleting symbols  \n",
    "    #cleartext = cleartext.translate(remove_digits)\n",
    "    cleartext = cleartext.replace(\"\\\\\", \"\")\n",
    "    cleartext = cleartext.rstrip()\n",
    "    #прибираємо зайві пробіи\n",
    "    cleartext = re.sub(\" +\", \" \", cleartext)\n",
    "    #ділимо речення на список слів, розбиваємо по пробілам\n",
    "    cleartext = re.split(\" \", cleartext)\n",
    "    #прибираємо стопслова\n",
    "    cleartext = [word for word in cleartext if word not in stop_words]\n",
    "    #прибираємо слова, довжина який менше 3 букв\n",
    "    cleartext = [word for word in cleartext if len(word) > 3]\n",
    "    #лематизація слів\n",
    "    cleartext = [simplemma.lemmatize(word, lang='uk') for word in cleartext]\n",
    "    cleartext = [word.lower() for word in cleartext ]\n",
    "    return ' '.join(cleartext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('D:\\\\NLP\\\\NLP\\\\NLP_all.xlsx')\n",
    "df = df.sample(frac=1) \n",
    "\n",
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "df['Category'] = df['Category'].replace(['Toxic', 'Not_Toxic'],[1,0])\n",
    "df.columns = ['Comment', 'Category']\n",
    "df_train, df_test = train_test_split(df, test_size = 0.10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "model_args = ClassificationArgs(num_train_epochs=1, overwrite_output_dir=True, manual_seed=42)\n",
    "model = ClassificationModel(model_type='roberta', model_name='roberta-base', use_cuda=False, num_labels=2, args=model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce650868363f4526902bef05ae90f1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1046 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b906515fa046488ddde38913e252ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56550e37c3b42ecbda96c55095cb760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/131 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(131, 0.6772095902275493)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Максим\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:1454: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910f79e4dfa347fc962a34bd3c486881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcb3824e8ae412189da7b26028fccb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.0, 'tp': 0, 'tn': 78, 'fp': 0, 'fn': 39, 'auroc': 0.5631163708086785, 'auprc': 0.382683485614188, 'eval_loss': 0.6496504783630371}\n",
      "[[ 0.21981834 -0.14733961]\n",
      " [ 0.21858491 -0.12934802]\n",
      " [ 0.21960326 -0.13558047]\n",
      " [ 0.22822918 -0.14114752]\n",
      " [ 0.22353126 -0.13419114]\n",
      " [ 0.21151285 -0.13792281]\n",
      " [ 0.2175865  -0.13173421]\n",
      " [ 0.22569893 -0.1351627 ]\n",
      " [ 0.22624062 -0.13916467]\n",
      " [ 0.21662267 -0.13627145]\n",
      " [ 0.21533553 -0.1436439 ]\n",
      " [ 0.21918668 -0.1372977 ]\n",
      " [ 0.21540926 -0.13897908]\n",
      " [ 0.21839978 -0.13385932]\n",
      " [ 0.22628587 -0.13728803]\n",
      " [ 0.22001745 -0.13438225]\n",
      " [ 0.21569352 -0.13399921]\n",
      " [ 0.22522973 -0.13993819]\n",
      " [ 0.21862902 -0.13470228]\n",
      " [ 0.21481565 -0.13194957]\n",
      " [ 0.22196242 -0.1382786 ]\n",
      " [ 0.22120221 -0.13723899]\n",
      " [ 0.22029175 -0.13243844]\n",
      " [ 0.22142689 -0.14056478]\n",
      " [ 0.21674305 -0.13519867]\n",
      " [ 0.22232632 -0.13436984]\n",
      " [ 0.2254737  -0.1392775 ]\n",
      " [ 0.21780412 -0.13310818]\n",
      " [ 0.22049092 -0.13581191]\n",
      " [ 0.22408588 -0.14202717]\n",
      " [ 0.21627523 -0.13297813]\n",
      " [ 0.21652229 -0.14099319]\n",
      " [ 0.22285484 -0.13830116]\n",
      " [ 0.21847086 -0.13266017]\n",
      " [ 0.22105892 -0.13075109]\n",
      " [ 0.21828616 -0.13804021]\n",
      " [ 0.22386672 -0.1371713 ]\n",
      " [ 0.21993785 -0.13337062]\n",
      " [ 0.22189593 -0.13162802]\n",
      " [ 0.21972217 -0.13262193]\n",
      " [ 0.22658038 -0.13327648]\n",
      " [ 0.22264014 -0.13648535]\n",
      " [ 0.22000553 -0.13413803]\n",
      " [ 0.21654658 -0.13945937]\n",
      " [ 0.21763007 -0.14073227]\n",
      " [ 0.22070803 -0.13620313]\n",
      " [ 0.21787639 -0.13830701]\n",
      " [ 0.22154953 -0.13131358]\n",
      " [ 0.22608894 -0.13983129]\n",
      " [ 0.21614926 -0.13669251]\n",
      " [ 0.21999209 -0.13027169]\n",
      " [ 0.22661041 -0.1388979 ]\n",
      " [ 0.22125286 -0.13589627]\n",
      " [ 0.21650842 -0.14081463]\n",
      " [ 0.22799759 -0.14201586]\n",
      " [ 0.22487594 -0.13884813]\n",
      " [ 0.22458188 -0.14096524]\n",
      " [ 0.2170158  -0.12976001]\n",
      " [ 0.2155486  -0.14332706]\n",
      " [ 0.21536219 -0.1418304 ]\n",
      " [ 0.22400631 -0.14220545]\n",
      " [ 0.21810469 -0.13660249]\n",
      " [ 0.21690266 -0.13615744]\n",
      " [ 0.21479876 -0.13812824]\n",
      " [ 0.22631142 -0.13610323]\n",
      " [ 0.22124206 -0.13675566]\n",
      " [ 0.22026515 -0.13487808]\n",
      " [ 0.2138796  -0.13822059]\n",
      " [ 0.21755873 -0.14330012]\n",
      " [ 0.21721803 -0.13580242]\n",
      " [ 0.21554226 -0.1470602 ]\n",
      " [ 0.22103684 -0.13874198]\n",
      " [ 0.21918149 -0.13313271]\n",
      " [ 0.22903334 -0.14639488]\n",
      " [ 0.22551771 -0.14259689]\n",
      " [ 0.2133982  -0.13973649]\n",
      " [ 0.2263612  -0.14602917]\n",
      " [ 0.21607608 -0.13812642]\n",
      " [ 0.22134371 -0.13045134]\n",
      " [ 0.22622864 -0.13849299]\n",
      " [ 0.22566734 -0.14123066]\n",
      " [ 0.22267656 -0.13370289]\n",
      " [ 0.21988668 -0.14412516]\n",
      " [ 0.21692783 -0.13223052]\n",
      " [ 0.21692781 -0.13223056]\n",
      " [ 0.2303098  -0.14528291]\n",
      " [ 0.21833092 -0.14292885]\n",
      " [ 0.22445132 -0.13508765]\n",
      " [ 0.21957083 -0.13456631]\n",
      " [ 0.22082339 -0.13343534]\n",
      " [ 0.21804969 -0.13237715]\n",
      " [ 0.21255063 -0.13733201]\n",
      " [ 0.22670658 -0.14280926]\n",
      " [ 0.21716838 -0.14067136]\n",
      " [ 0.22449546 -0.13750994]\n",
      " [ 0.2221116  -0.14611095]\n",
      " [ 0.21755742 -0.13514084]\n",
      " [ 0.22090483 -0.13700461]\n",
      " [ 0.2178302  -0.13954829]\n",
      " [ 0.22491816 -0.13564147]\n",
      " [ 0.2239774  -0.13544825]\n",
      " [ 0.22455959 -0.1509268 ]\n",
      " [ 0.21973988 -0.13415647]\n",
      " [ 0.21900751 -0.14843924]\n",
      " [ 0.21990575 -0.13142942]\n",
      " [ 0.21525691 -0.14222713]\n",
      " [ 0.21595579 -0.13706221]\n",
      " [ 0.2251188  -0.1432789 ]\n",
      " [ 0.22698028 -0.13935494]\n",
      " [ 0.22159329 -0.13929909]\n",
      " [ 0.22426876 -0.13934717]\n",
      " [ 0.22002167 -0.13596874]\n",
      " [ 0.22102734 -0.14308323]\n",
      " [ 0.22287716 -0.13988894]\n",
      " [ 0.22527803 -0.13823518]\n",
      " [ 0.21881168 -0.13885114]\n",
      " [ 0.2241091  -0.13719331]]\n",
      "[{'guid': 0, 'text_a': 'Ви несповна розуму....', 'text_b': None, 'label': 1}, {'guid': 1, 'text_a': 'а інстаграмм на російській, це жах, сому так ', 'text_b': None, 'label': 1}, {'guid': 4, 'text_a': 'Такі прильоти шалені вже сталися, а ви так пізно показуєте це відео. Воно втрачає інтерес', 'text_b': None, 'label': 1}, {'guid': 5, 'text_a': 'ЛАХУДРА БРЕХЛИВА.\\nОДНА З ТИХ ЖІНОК, ЯКІ ЗАРАДИ ЧОЛОВІКА,ПЕРЕСТУПИТЬ ЧЕРЕЗ УСІХ ДІТЕЙ.', 'text_b': None, 'label': 1}, {'guid': 23, 'text_a': 'Ну вот куда такие плодятся?', 'text_b': None, 'label': 1}, {'guid': 24, 'text_a': 'Волосся кольору ,,борщ,, вже не вражае', 'text_b': None, 'label': 1}, {'guid': 26, 'text_a': 'Антонім до слова аморальний - це російський. Досліджуйте питання якісніше!!', 'text_b': None, 'label': 1}, {'guid': 27, 'text_a': 'Не забувайте що код України це її мова!!!! А ви шановний маг працюєте на москові', 'text_b': None, 'label': 1}, {'guid': 29, 'text_a': 'Вкусная точка для її гудочка.', 'text_b': None, 'label': 1}, {'guid': 33, 'text_a': 'Їй одне кажуть, а вона все про чоловіка свого думає, дура', 'text_b': None, 'label': 1}, {'guid': 36, 'text_a': \"арт об'єкти в кожному місці, ця як назва для сучасного умоустрою. траву там курити та пити вино\", 'text_b': None, 'label': 1}, {'guid': 41, 'text_a': 'Прочитала новини і зрозуміла,що я теж можу бути екстрасенсом.Треба купити карти… це просто лохотрон', 'text_b': None, 'label': 1}, {'guid': 50, 'text_a': 'А чого позаду вас Маріуполь російською? Хлопці... Ні і ще раз ні..', 'text_b': None, 'label': 1}, {'guid': 52, 'text_a': 'Жінка,яка тащить все на собі- сама винна! Такі жінки вибирають слабких чоловіків, ще й 4 дітей мати в таких умовах і такій сімейній атмосфері!', 'text_b': None, 'label': 1}, {'guid': 59, 'text_a': 'Що за «кабздєц холодєц»?', 'text_b': None, 'label': 1}, {'guid': 60, 'text_a': 'Олексійчику твоя українська мова найкраща.\\nА випуск веселий,посміялась з тупих орків', 'text_b': None, 'label': 1}, {'guid': 61, 'text_a': 'звідки родом ця людина? Звідки він знає українське ворожінні на квасолі? Він виріс в Україні?', 'text_b': None, 'label': 1}, {'guid': 65, 'text_a': 'Вдома такий срач, прусаки по ляльці пішки ходять ... Та на неї мухи летять навіть у студії 19:22  караул ...', 'text_b': None, 'label': 1}, {'guid': 66, 'text_a': 'Виходить, що навіть казахи чмоняють сабурова? Кек)', 'text_b': None, 'label': 1}, {'guid': 67, 'text_a': \"А навіщо навчати гарматне м'ясо?\", 'text_b': None, 'label': 1}, {'guid': 74, 'text_a': 'Дуже круті гості - вподобайка. А от сценаристу - несхвайлик. ', 'text_b': None, 'label': 1}, {'guid': 77, 'text_a': 'Коли введуть закон про кастрацію гвалтівників?', 'text_b': None, 'label': 1}, {'guid': 78, 'text_a': 'Господи, я навіть ворогові такого чоловіка не пожилала', 'text_b': None, 'label': 1}, {'guid': 81, 'text_a': 'ммммммммм бульйону\\nі все робить однією губкою мм ямі ямі', 'text_b': None, 'label': 1}, {'guid': 88, 'text_a': 'неможливо насолоджуватись перешкаджають титри', 'text_b': None, 'label': 1}, {'guid': 89, 'text_a': 'в одній з передач ви сказали точно де знаходиться ППО, ви не думали, що там живуть люди, не робіть цього, як зараз назвайте місто ', 'text_b': None, 'label': 1}, {'guid': 90, 'text_a': 'Браво це прекрасно , як страждають із парашки - здохніть тварі', 'text_b': None, 'label': 1}, {'guid': 92, 'text_a': 'Як завжди феєрично. Я годинами можу дивитись як страждають ці нелюди.', 'text_b': None, 'label': 1}, {'guid': 96, 'text_a': 'Шоу зіпсувалось, неможливо дивитись, усе награно', 'text_b': None, 'label': 1}, {'guid': 102, 'text_a': 'Ліліпут Зеленський від страху забився під плінтус', 'text_b': None, 'label': 1}, {'guid': 103, 'text_a': 'Текст нарезан, не бреши, убийца.', 'text_b': None, 'label': 1}, {'guid': 104, 'text_a': 'Мені подобається вона у всіх\\nПоложеннях суппер\\nТаланд', 'text_b': None, 'label': 1}, {'guid': 105, 'text_a': 'Тварюки! Шо ж ви зробили з моєї України? тварюки ницистські !!!', 'text_b': None, 'label': 1}, {'guid': 106, 'text_a': 'Ось вони інстадіви, здивовані я теж', 'text_b': None, 'label': 1}, {'guid': 108, 'text_a': 'Вириваються із села, щоб усе мати, і ні за що не відповідати. Їдуть туди, де на більше бабла, можна купити більше бухла.', 'text_b': None, 'label': 1}, {'guid': 109, 'text_a': 'всіх окупантів розфасуємо по покетам, без виключення.', 'text_b': None, 'label': 1}, {'guid': 111, 'text_a': 'Користується українськими цінними знаннями, а говоре по російські, перейдіть на українську, вам ціни небуде, вибачте', 'text_b': None, 'label': 1}, {'guid': 115, 'text_a': 'Все, що гарне у Львові, збудували поляки!', 'text_b': None, 'label': 1}, {'guid': 116, 'text_a': \"Людочка, дорогенька, якщо ти це читаєш, виганяй цю дитину-переростка. Він тобі не чоловік, а старша дитина в сім'ї. Нехай вертається жити до своєї мами. Я в 32 роки, вагітна, пішла від такого ж. Єдине, про що шкодую, що змарнувала на нього час.\", 'text_b': None, 'label': 1}]\n"
     ]
    }
   ],
   "source": [
    "result, model_outputs, wrong_preds = model.eval_model(df_test)\n",
    "print(result)\n",
    "print(model_outputs)\n",
    "print(wrong_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for x in model_outputs:\n",
    "    predictions.append(np.argmax(x))\n",
    "print('f1 score:', f1_score(df_test['Category'], predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9682fbd1252c3bd7a59128bacdd75169c5ac4080a3158b28ae547da5edb0fc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
