{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import simplemma\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"ggplot\")\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#попередня обробка тексту\n",
    "def ClearText(text):\n",
    "    #переведення до нижнього регістру всіх слів\n",
    "    cleartext = text.lower()\n",
    "    #print(cleartext)\n",
    "    #прибирання пустих рядків та розрив рядків\n",
    "    cleartext = re.sub('\\-\\s\\r\\n\\s{1,}|\\-\\s\\r\\n|\\r\\n', '', cleartext) \n",
    "    #залишаємо лише слова, прибираємо пунктуацію та числа\n",
    "    cleartext = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-', ' ', cleartext) #deleting symbols  \n",
    "    #cleartext = cleartext.translate(remove_digits)\n",
    "    cleartext = cleartext.replace(\"\\\\\", \"\")\n",
    "    cleartext = cleartext.rstrip()\n",
    "    #прибираємо зайві пробіи\n",
    "    cleartext = re.sub(\" +\", \" \", cleartext)\n",
    "    #ділимо речення на список слів, розбиваємо по пробілам\n",
    "    cleartext = re.split(\" \", cleartext)\n",
    "    #прибираємо стопслова\n",
    "    cleartext = [word for word in cleartext if word not in stop_words]\n",
    "    #прибираємо слова, довжина який менше 3 букв\n",
    "    cleartext = [word for word in cleartext if len(word) > 3]\n",
    "    #лематизація слів\n",
    "    cleartext = [simplemma.lemmatize(word, lang='uk') for word in cleartext]\n",
    "    cleartext = [word.lower() for word in cleartext ]\n",
    "    return ' '.join(cleartext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Category</th>\n",
       "      <th>ClearText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>Боже, яка краса!!!! Так надихаюче!!!! Чарівна ...</td>\n",
       "      <td>Not_Toxic</td>\n",
       "      <td>бог краса надихаюче чарівний сім‘я прекрасний ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Як гадаєте, чому люди бояться висвітлювати в с...</td>\n",
       "      <td>Not_Toxic</td>\n",
       "      <td>гадати боятися висвітлювати соцмережах реальний</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>генії,в країні йде війна 8 років а вони відпра...</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>геній країна війна відправляти пітер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Україна була! Україна є! Україна буде! Слава У...</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>україна україна україна слава україна герой сл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>ЛАХУДРА БРЕХЛИВА.\\nОДНА З ТИХ ЖІНОК, ЯКІ ЗАРАД...</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>лахудра брехливий \\nодна жінка заради чоловік ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>Це воля !!! Воля душі і тіла !!! Хто не жив у ...</td>\n",
       "      <td>Not_Toxic</td>\n",
       "      <td>воля воля душ тіло село знати ідея хороший</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Блондин повернувся до України?</td>\n",
       "      <td>Not_Toxic</td>\n",
       "      <td>блондин повернутися україна</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>Ну той мужик у рожевому халаті 200 кг мінімум</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>мужик рожевий халат мінімум</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>Подивіться Дніпро.</td>\n",
       "      <td>Not_Toxic</td>\n",
       "      <td>подивитися дніпро</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Скажіть, а що в цьому надзвичайного.\\nЛюдина к...</td>\n",
       "      <td>Not_Toxic</td>\n",
       "      <td>сказати надзвичайний \\nлюдина купило дача пода...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment   Category  \\\n",
       "846   Боже, яка краса!!!! Так надихаюче!!!! Чарівна ...  Not_Toxic   \n",
       "185   Як гадаєте, чому люди бояться висвітлювати в с...  Not_Toxic   \n",
       "326   генії,в країні йде війна 8 років а вони відпра...      Toxic   \n",
       "11    Україна була! Україна є! Україна буде! Слава У...      Toxic   \n",
       "1136  ЛАХУДРА БРЕХЛИВА.\\nОДНА З ТИХ ЖІНОК, ЯКІ ЗАРАД...      Toxic   \n",
       "...                                                 ...        ...   \n",
       "682   Це воля !!! Воля душі і тіла !!! Хто не жив у ...  Not_Toxic   \n",
       "625                      Блондин повернувся до України?  Not_Toxic   \n",
       "630       Ну той мужик у рожевому халаті 200 кг мінімум      Toxic   \n",
       "1032                                 Подивіться Дніпро.  Not_Toxic   \n",
       "678   Скажіть, а що в цьому надзвичайного.\\nЛюдина к...  Not_Toxic   \n",
       "\n",
       "                                              ClearText  \n",
       "846   бог краса надихаюче чарівний сім‘я прекрасний ...  \n",
       "185     гадати боятися висвітлювати соцмережах реальний  \n",
       "326                геній країна війна відправляти пітер  \n",
       "11    україна україна україна слава україна герой сл...  \n",
       "1136  лахудра брехливий \\nодна жінка заради чоловік ...  \n",
       "...                                                 ...  \n",
       "682          воля воля душ тіло село знати ідея хороший  \n",
       "625                         блондин повернутися україна  \n",
       "630                         мужик рожевий халат мінімум  \n",
       "1032                                  подивитися дніпро  \n",
       "678   сказати надзвичайний \\nлюдина купило дача пода...  \n",
       "\n",
       "[1163 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/helen/OneDrive/Рабочий стол/пары/NLP_all.xlsx')\n",
    "df = df.sample(frac=1) \n",
    "df['ClearText'] = df.apply(lambda x: ClearText(x['Comment']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df['ClearText'])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TF-IDF'] = list(X_train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category1'] = df.apply(lambda x: 0 if x['Category'] == 'Not_Toxic' else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc [:round(df.shape[0]*0.75)]\n",
    "df_test = df.iloc [round(df.shape[0]*0.75):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# booster='gbtree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 65.29%\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(list(df_train['TF-IDF']), list(df_train['category1']))\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(list(df_test['TF-IDF']))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(list(df_test['category1']), predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# booster='gblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:12] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 67.35%\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(booster='gblinear')\n",
    "model.fit(list(df_train['TF-IDF']), list(df_train['category1']))\n",
    "print(model)\n",
    "y_pred = model.predict(list(df_test['TF-IDF']))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(list(df_test['category1']), predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# booster='dart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:20] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy: 65.29%\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(booster='dart')\n",
    "model.fit(list(df_train['TF-IDF']), list(df_train['category1']))\n",
    "print(model)\n",
    "y_pred = model.predict(list(df_test['TF-IDF']))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(list(df_test['category1']), predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helen\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:15] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=250, n_jobs=15, num_parallel_tree=None,\n",
      "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
      "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "Accuracy: 70.79%\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(base_score=0.5, booster='gblinear', learning_rate=0.1, scale_pos_weight=1,\n",
    "               n_estimators=250, n_jobs=15)\n",
    "model.fit(list(df_train['TF-IDF']), list(df_train['category1']))\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(list(df_test['TF-IDF']))\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(list(df_test['category1']), predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "model.fit(list(df_train['TF-IDF']), list(df_train['category1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_y  = list(df_test['category1'])\n",
    "predicted_y = model.predict(list(df_test['TF-IDF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_reg = [round(value) for value in predicted_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.92%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(expected_y, predictions_reg)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
